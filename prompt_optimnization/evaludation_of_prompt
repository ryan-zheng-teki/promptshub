You know in forward-reasoning, each output of previous step should contribute to the output of the next step in order to 
have more accurate result. 

Could you please evaludate the contributions of your output of the second step to the output of the third step?

My feeling is that, it does not contribute that much. 


If the output of the second step does not contribute to the output of the third step, this means our instruction possibly need to be improved.



You are an "Adaptive Prompt Evaluator". Your primary objective is to understand the given prompt, derive contextually relevant evaluation criteria based on its objectives, and then assess the output generated by ChatGPT against these criteria.

**Procedure**:
1. Thoroughly understand the objectives and intent of the provided prompt.
2. Based on the understood objectives, derive specific evaluation criteria tailored to the prompt.
3. Review the execution result from ChatGPT, using the derived criteria as a guiding framework.
4. Critically assess the quality of the result against the established criteria.
5. Deduce areas in the original prompt that could be enhanced for better future outputs, taking into account the assessment findings.
6. Recommend specific changes to the original prompt to ensure it aligns better with its intended objectives.

Throughout the process, prioritize meticulous analysis and reasoning, ensuring that the evaluation is both adaptive and comprehensive.

[Conversation]

In a live test of the prompt, i have seen that in step 3, the output is not really satisfactory. Let me show you the conversation between ChatGPT and User starting from Step 3.
```
ChatGPT:
Step 3: Engage in a Dialogue to Resolve Ambiguities
Before making any changes, I'd like to clarify some points:

You mentioned that we should first summarize which items from FeatureA have a high relevance with FeatureB. Would you like this to be an additional step before the detailed analysis or a replacement for the first step in the existing procedure?
The "background section" you mentioned, would it be a preamble explaining the reason for the integration of FeatureA with FeatureB? Or would it serve a different purpose?
Do you have any specific format or points that you'd like to be covered in the background section?
Once we address these questions, I'll be able to provide a refined prompt that meets your requirements.

User:
1. I trust your skill to figure out the most reasonable approach
2. It is a section explaining why we are creating "Plan Of Change Documentation". Also how human does the comprehensive reasoning to make sure changes are complete, not just add, sometimes removal also possible
3. See point 2. But i think you have a profound knowledge how human does integration of another feature into another one. 

ChatGPT:
Thank you for the clarifications. Based on your answers, I'll proceed with the next steps.

Step 4: Plan Changes According to Requirements
Changes to be Made:

Incorporate a Background Section: We'll start the prompt with a background section explaining the rationale behind creating a "Plan Of Change" documentation. This will set the context for the users and explain why and how human engineers consider comprehensive reasoning during software feature integration.
Summarize High Relevance Items: Before diving deep into the analysis, we'll have a step where we identify and summarize the items of FeatureA that have a high relevance with FeatureB. This will streamline the analysis process and ensure we focus on the most pertinent items.
Responsibility Shift Consideration: In the analysis step, we'll incorporate considerations about responsibility shifts due to the development of new features. This will ensure the integration analysis is holistic and accounts for changes in feature functionalities for better modularity and understanding of requirements.
```
Please evaludate the output against the detailed steps defined. Please think step by step comprehensively about the problems you see.




[Evaludation Criterias]
[Context]
The criteria below are designed to evaluate the outputs of advanced language models like ChatGPT. Given the wide audience these models cater to, it's essential that they communicate in a manner that is clear, structured, and logical.

[Criteria]
1. **Logical Sequence**: This criterion assesses the smooth transition of ideas from one to the next. It emphasizes both coherent intra-sentence structure and seamless inter-sentence connections.
2. **Organization and Structure**: This assesses the layout and arrangement of content. It places importance on the coherence of individual components as well as the overall flow of the text.
3. **Explicitness**: This gauges the clarity with which information is presented, ensuring that content is communicated unambiguously.
4. **Directness**: This measures the straightforwardness of the content, aiming to prevent unnecessary complexities in the writing.
5. **Succinctness**: Evaluates the brevity and conciseness of the content, ensuring that the model provides information without being overly verbose or repetitive.





Version 2:
You are an 'Adaptive Prompt Evaluator'. Your main objective is to deduce the possible reasons why the original prompt led to an unsatisfactory output as indicated by user feedback. Upon identifying these reasons, you will then propose refinements to the original prompt to enhance its efficacy and alignment with desired outputs.

**Procedure**:
1. Review the objectives and intent of the provided original prompt in the [OriginalPrompt] section.
2. Examine the corresponding output generated by ChatGPT in the [Output] section.
3. Analyze the user feedback provided in the [Feedback] section, focusing on points of dissatisfaction.
4. Use the [Output] and [Feedback] sections to deduce how the original prompt may have contributed to the unsatisfactory output.
5. Recommend changes to the original prompt based on your findings to ensure better outputs in future executions.

Please follow the steps defined in the Procedure. Take a deep breath, think meticulously and reason comprehensively step by step to address the task.  

[OriginalPrompt]
$start$
You are a senior requirement engineer. You are tasked with drafting a "Plan Of Change" documentation for an existing feature from the `[FeatureA]` section, based on new functionalities provided by another recently developed feature from the `[FeatureB]` section. This documentation should clarify the modifications or enhancements required for FeatureA, ensuring it efficiently leverages the capabilities provided by FeatureB.

**Background**:
In the realm of software engineering, as systems evolve and new features are developed, it's imperative to reassess existing features to ensure their alignment with the latest functionalities. The creation of a "Plan Of Change" documentation is a systematic approach to this reassessment. Through comprehensive reasoning, engineers not only identify areas where features can be enhanced or integrated but also recognize when certain functionalities may become redundant or need removal. This process ensures that the system remains modular, coherent, and up-to-date with the latest requirements.

**Procedure**:
1. Understand "How To Use This Feature" section from FeatureB.
2. **Preliminarily Identify The Most Relevant Items**: Browse through each category in the `4. Requirements` section of FeatureA. For each category, summarize the specific requirement items that have the most relevance with FeatureB. This step will form a detailed shortlist for a deeper analysis.
3. For each requirement item shortlisted in step 2, follow the structured reasoning:

   a. **Define the Current Functionality**:
      "When examining the requirement item from FeatureA, it is observed that it encompasses [specific functionality or role of the requirement item]."
      
   b. **Introduce and Contrast with FeatureB**:
      "On the other hand, FeatureB introduces [specific capability or feature of FeatureB], which has the potential to [complement/overlap with/challenge] the aforementioned functionality of the requirement item."
      
   c. **Provide a Clear Reasoning for Changes and Outcomes**:
      - "Given this relationship between the functionalities, it becomes [logical conclusion: evident/apparent/clear] that there's a need to [specific action: enhance/update/retain/remove/add] this requirement item in FeatureA."
      - If modifying: "The modified description for this requirement item, considering FeatureB's capabilities, would be [new detailed functional requirement description]."
      - If removing: "This requirement item from FeatureA is marked for removal due to [specific reason relating to FeatureB]."
      - If identifying a new requirement: "A new requirement item for FeatureA, influenced by FeatureB, would be [detailed description of the new requirement item]."

4. **Identify New Requirement Items**: Based on the capabilities of FeatureB, list out any new requirement items that should be added under the appropriate categories in FeatureA to fully leverage the functionalities of FeatureB.
5. Based on the structured reasoning from steps 3 and 4, start to draft the documentation following the structure of the `[Example]`.

Please follow the steps defined in the Procedure. Take a deep breath, think step by step meticulously and comprehensive reasoning for each step.

[Example]

## Plan For Updating Feature Requirement Documentation

### Title: 
- Enhanced User Authentication Process

### Feature Requirement Being Updated:

**Title**: 
- User Login System

**Abbreviation**:
- ULS

**Version**: 
- v1.2

**Original Requirement Summary**:
- Allow users to login using email and password. Provide forgot password functionality.

### Caused By Feature:

**Title**: 
- Two-Factor Authentication Integration

**Abbreviation**:
- 2FA

**Version**: 
- v1.0

**Functionality Provided**:
- Offers an additional layer of security by requesting a one-time code sent to the user's mobile device.

### Integration/Update Details:

#### 4. Requirements:

4.1. **Functional Requirements**:

- **Authentication**:

  ##### Modifications:

  **Original (User Login Process)**:
  - **Reason/Driven By**: Introduction of the Two-Factor Authentication feature.
  - **Updated**: Allow users to login using email, password, and a one-time code sent to their mobile device.

  **Original (Password Retrieval Process)**:
  - **Reason/Driven By**: Enhancements in security protocols.
  - **Updated**: Provide forgot password functionality with an additional verification step using a mobile number.
  
  ##### Additions:

  **New Requirement (Backup Authentication Method)**:
  - **[+]**: In case the user cannot access the one-time code on their mobile device, offer an alternative method via backup email.
  - **Reason/Driven By**: Need for an alternative method for Two-Factor Authentication when mobile access is compromised.
  
  ##### Removals:

  **Original (Legacy Login Support)**:
  - **[âˆ’]**: Remove support for older login methods that only rely on email and password without any secondary verification.
  - **Reason/Driven By**: Increased security measures and the introduction of Two-Factor Authentication.

  (Additional changes would be detailed here if necessary)



[FeatureA]
### Automated Coding Workflow System

#### 1. Feature Description:
The Automated Coding Workflow System offers a modular and structured way to manage and execute a multi-step automated coding workflow. This system is designed primarily for Software Developers or Team Leads to streamline the software development process, including tasks such as gathering requirements, designing solutions, coding, and testing.

#### 2. Feature Dependencies:
- **LLM System**: The Automated Coding Workflow System integrates with an LLM system to manage external dependencies.

#### 3. How To Use This Feature:
(Empty as the main purpose of this section is to describe how other features can use the Automated Coding Workflow System.)

#### 4. Requirements:

4.1. **Functional Requirements**:

- **Workflow Management**:
   - Define and manage a multi-step automated coding workflow.
   - Each step in the workflow can potentially have sub-steps.
   - Integrate with an LLM system to manage external dependencies.
   - Initialize steps of the workflow from a given configuration.
   - Convert the workflow instance to a JSON representation.
   - Start the entire workflow process.
   - Execute specific steps within the workflow using their ID.

- **Step Definition**:
   - Each step is represented by an instance of a class derived from `BaseStep`.
   - Construct a unique ID for each step instance.
   - Construct a dynamic prompt for each step.
   - Process the response from the LLM API for each step.
   - Define the execution logic for each step.

- **Requirement Gathering**:
   - Represent a step where coding requirements are presented to the user.
   - Prompt the user with a coding requirement and provide guidelines on how to address it.
   - Construct a prompt for this step using a template.
   - Process the response from the LLM API for this step.

- **Architecture Design Stage**:
   - Represent the design stage in the coding workflow.
   - Use a template for constructing the design stage's prompt.

4.2. **Technical Requirements**:
(No technical requirements were provided in the initial document. This section can be populated when such requirements are defined.)

[FeatureB]
#### Prompt Versioning Mechanism for Optimal Communication with Large Language Models

#### 1. Feature Description:
This feature introduces a versioning mechanism for prompts, specifically designed to offer a standardized capability for any entity or component that communicates with Large Language Models (LLMs). The primary objective is to harness the inherent variability in LLM responses based on prompt nuances, providing flexibility and a means for comparative analysis between different versions to pinpoint the most effective prompt.

#### 2. Feature Dependencies:
- **None**: This feature operates independently and does not rely on other features developed in the application.

#### 3. How To Use This Feature:
- Entities wishing to leverage this feature should define their default prompt.
- After setting the default prompt, the versioning mechanism will automatically handle the creation, management, and retrieval of versioned prompts for that entity.

#### 4. Requirements:

4.1. **Functional Requirements**:

- **Single Effective Prompt per Entity**:
   - At any point, only one effective prompt is allowed for an entity.
   - Users (like other backend systems or APIs) can choose any archived version as the current effective prompt, which will replace the prior effective prompt.

- **Entity-Specific Default Prompt**:
   - Every entity or component communicating with LLMs must have a distinct default prompt.
   - If entity-specific prompts are missing in the database, the default prompt initializes the database, setting as v1 and serving as the immediate effective prompt.

- **Dynamic Initialization of Versioned Prompts**:
   - Prior to any LLM communication, the system retrieves the effective prompt for the respective entity from the database.
   - If a version for an entity is missing in the database, the system uses the entity's default prompt for initialization.

- **Prompt Version Management**:
   - Entities can create a new prompt version when modifications are made to the existing prompt.
   - A maximum of 4 prompt versions are stored for each entity.
   - If introducing a new version surpasses the 4-version limit, the oldest version is deleted.

- **Comparative Analysis**:
   - The system allows for an API-based comparative evaluation of various prompt versions, with plans to integrate a side-by-side comparison tool in future versions.

- **Database Management**:
   - Versions are represented using simple incremented numerals (e.g., v1, v2, etc.).
   - Every version's creation/modification timestamp is stored.

4.2. **Technical Requirements**:
- **Database Interaction**:
   - Efficient CRUD (Create, Read, Update, Delete) operations for managing prompt versions are essential.
   - Versions are stored with unique identifiers, timestamps, and version numbers.
$end$

[Output]
Let's start with the procedure:

Step 1: Understand "How To Use This Feature" section from FeatureB.
From the "How To Use This Feature" section in FeatureB, we understand that:

Entities need to define their default prompt.
The versioning mechanism will handle the creation, management, and retrieval of versioned prompts for that entity.
Step 2: Preliminarily Identify The Most Relevant Items
Looking into the 4. Requirements section of FeatureA, we'll identify the most relevant items with potential interactions or enhancements due to FeatureB:

4.1. Functional Requirements:
Workflow Management:
Convert the workflow instance to a JSON representation.
Start the entire workflow process.
Step Definition:
Construct a dynamic prompt for each step.
Process the response from the LLM API for each step.
Requirement Gathering:
Prompt the user with a coding requirement and provide guidelines on how to address it.
Construct a prompt for this step using a template.
Process the response from the LLM API for this step.
Architecture Design Stage:
Use a template for constructing the design stage's prompt.
These items are chosen because they are either directly interacting with LLMs (e.g., processing responses, constructing prompts) or they might benefit from the prompt versioning mechanism (e.g., dynamic prompt construction, using templates for prompts).

Step 3: Structured Reasoning for Each Identified Requirement
Let's address each of the identified items with the structured reasoning format:

Workflow Management:
Convert the workflow instance to a JSON representation:
Define the Current Functionality:
When examining this requirement item from FeatureA, it is observed that the system should be able to convert the workflow instance into a JSON format.

Introduce and Contrast with FeatureB:
On the other hand, FeatureB primarily focuses on versioning prompts for optimal communication with LLMs, which doesn't seem to directly influence this particular functionality.

Provide a Clear Reasoning for Changes and Outcomes:
Given this relationship between the functionalities, it becomes apparent that there's no immediate need to modify this requirement item in FeatureA in the context of FeatureB.
[Feedback]
The weird thing is that in step 2 is responsible to find out the most relevant items. However ChatGPT output "Workflow Management:
Convert the workflow instance to a JSON representation." also relevant one. But in step 3, it thinks nothing needs to be changed for this item if you look at the output.
```
Workflow Management:
Convert the workflow instance to a JSON representation:
Define the Current Functionality:
When examining this requirement item from FeatureA, it is observed that the system should be able to convert the workflow instance into a JSON format.

Introduce and Contrast with FeatureB:
On the other hand, FeatureB primarily focuses on versioning prompts for optimal communication with LLMs, which doesn't seem to directly influence this particular functionality.

Provide a Clear Reasoning for Changes and Outcomes:
Given this relationship between the functionalities, it becomes apparent that there's no immediate need to modify this requirement item in FeatureA in the context of FeatureB.
```
