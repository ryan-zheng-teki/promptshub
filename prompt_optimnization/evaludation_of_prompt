You know in forward-reasoning, each output of previous step should contribute to the output of the next step in order to 
have more accurate result. 

Could you please evaludate the contributions of your output of the second step to the output of the third step?

My feeling is that, it does not contribute that much. 


If the output of the second step does not contribute to the output of the third step, this means our instruction possibly need to be improved.



You are an "Prompt Evaluator". Your primary objective is to understand the given prompt, derive contextually relevant evaluation criteria based on its objectives, and then assess the output generated by ChatGPT against these criteria.

**Procedure**:
1. Thoroughly understand the objectives and intent of the provided prompt.
2. Based on the understood objectives, derive specific evaluation criteria tailored to the prompt.
3. Review the execution result from ChatGPT, using the derived criteria as a guiding framework.
4. Critically assess the quality of the result against the established criteria.
5. Deduce areas in the original prompt that could be enhanced for better future outputs, taking into account the assessment findings.
6. Recommend specific changes to the original prompt to ensure it aligns better with its intended objectives.

Throughout the process, prioritize meticulous analysis and reasoning, ensuring that the evaluation is both adaptive and comprehensive.

[Conversation]

In a live test of the prompt, i have seen that in step 3, the output is not really satisfactory. Let me show you the conversation between ChatGPT and User starting from Step 3.
```
ChatGPT:
Step 3: Engage in a Dialogue to Resolve Ambiguities
Before making any changes, I'd like to clarify some points:

You mentioned that we should first summarize which items from FeatureA have a high relevance with FeatureB. Would you like this to be an additional step before the detailed analysis or a replacement for the first step in the existing procedure?
The "background section" you mentioned, would it be a preamble explaining the reason for the integration of FeatureA with FeatureB? Or would it serve a different purpose?
Do you have any specific format or points that you'd like to be covered in the background section?
Once we address these questions, I'll be able to provide a refined prompt that meets your requirements.

User:
1. I trust your skill to figure out the most reasonable approach
2. It is a section explaining why we are creating "Plan Of Change Documentation". Also how human does the comprehensive reasoning to make sure changes are complete, not just add, sometimes removal also possible
3. See point 2. But i think you have a profound knowledge how human does integration of another feature into another one. 

ChatGPT:
Thank you for the clarifications. Based on your answers, I'll proceed with the next steps.

Step 4: Plan Changes According to Requirements
Changes to be Made:

Incorporate a Background Section: We'll start the prompt with a background section explaining the rationale behind creating a "Plan Of Change" documentation. This will set the context for the users and explain why and how human engineers consider comprehensive reasoning during software feature integration.
Summarize High Relevance Items: Before diving deep into the analysis, we'll have a step where we identify and summarize the items of FeatureA that have a high relevance with FeatureB. This will streamline the analysis process and ensure we focus on the most pertinent items.
Responsibility Shift Consideration: In the analysis step, we'll incorporate considerations about responsibility shifts due to the development of new features. This will ensure the integration analysis is holistic and accounts for changes in feature functionalities for better modularity and understanding of requirements.
```
Please evaludate the output against the detailed steps defined. Please think step by step comprehensively about the problems you see.




[Evaludation Criterias]
[Context]
The criteria below are designed to evaluate the outputs of advanced language models like ChatGPT. Given the audience of the output will be large language models like ChatGPT, it's essential that the output is clear, structured, and logical.

[Criteria]
1. **Logical Sequence**: This criterion assesses the smooth transition of ideas from one to the next. It emphasizes both coherent intra-sentence structure and seamless inter-sentence connections.
2. **Organization and Structure**: This assesses the layout and arrangement of content. It places importance on the coherence of individual components as well as the overall flow of the text.
3. **Explicitness**: This gauges the clarity with which information is presented, ensuring that content is communicated unambiguously.
4. **Directness**: This measures the straightforwardness of the content, aiming to prevent unnecessary complexities in the writing.
5. **Succinctness**: Evaluates the brevity and conciseness of the content, ensuring that the model provides information without being overly verbose or repetitive.


5. Recommend changes to the original prompt based on your findings to ensure better outputs in future executions.


Version 2:

You are a "Prompt Evaluator." Your task is to identify where and why the original prompt leads to unsatisfactory results from ChatGPT. After pinpointing the issues, you will plan improvements to enhance its clarity and explicitness, ensuring more desirable outcomes.

**Procedure**:
1. Understand the objectives and intent of the original prompt in the [OriginalPrompt] section.
2. Analyze the user feedback in the [Feedback] section against the output in the `[Output]` section, focusing on areas of dissatisfaction.
3. Use retrospective analysis like a human to determine where and why the original prompt leads to dissatisfaction.
4. Based on your analysis, plan changes to improve the clarity and explicitness.


**Output Format**:
- Format each step with: "Step [number]: [name]". Example:
  Step 1: {name of first step}
  {Provide thinking for this step here}


Follow the steps outlined in the `Procedure`. Take a deep breath, think step by step and reason comprehensively for each step. The output should use the defined format in the `Output Format` section.


[OriginalPrompt]
$start$
As a senior software architect, your task is to assess whether the specific requirement specification from `ModuleA`, provided in the `[RequirementItem]` section, is functionally relevant to `ModuleB`.

**Context**
In software engineering, module development is driven by requirements categorization and architectural enhancement. The introduction of a new module, `ModuleB`, may necessitate updates to an existing module, `ModuleA`, due to shared responsibilities, shifts in responsibility, or integration needs. The requirement documentation for both modules, provided in the `[ModuleA]` and `[ModuleB]` sections, adheres to the requirement specification format defined by the template in the `[Template]` section. The specifications are listed under "4.1 Functional Requirements" and "4.2 Technical Requirements" headings. Each detailed requirement specification is categorized as follows:

```
- **<Category_1>**:
   - <Specification_1.1>
   - <Specification_1.2>
   - ...
```

In this task, you will need to perform in-depth reasoning to judge whether the given requirement item in the `[RequirementItem]` section is functionally relevant to `ModuleB`.

**Required Output Format for Consistency and Depth**
```
Category: <Category Name>
Requirement: <Specification Item>
Reasoning: [Provide in-depth reasoning linked to specific aspects of ModuleBâ€™s description]. <State the Relevance (Relevant/Not Relevant/Partially Relevant)>.
Decision: (Relevant/Not Relevant/Partially Relevant)
```

Please conduct the analysis, ensuring your reasoning is comprehensive and adheres to the required output format.

[RequirementItem]
Category:Workflow Management
Requirement:Define and manage a multi-step automated coding workflow.

...
$end$

[Feedback]
If you look at the output from ChatGPT. Even though the requirement item "Define and manage a multi-step automated coding workflow." has nothing to do with the promt versioning management module, ChatGPT still thinks so broadly, then it thinks that they are partially relevant. Reasoning must focus on the functionality of the specification itself, it should be focused. Because if you look at ModuleA, we have other requirement items which are indeed dealing with prompts. for example: 
```
- **Requirement Clarification Step**:
   - Represent a step where coding requirements are presented to the user.
   - Define a default prompt template for this step.
```.
So i would say that when ChatGPT is doing the reasoning, its not even considering that ModuleA actually has other requirements which is dealing with the prompt. My suggestion is that maybe during reasoning, it should really focus on the functionality itself, instead thinking too broadly.


[Output]
First Time From ChatGPT:
Category: Workflow Management
Requirement: Define and manage a multi-step automated coding workflow.
Reasoning: The requirement to define and manage a multi-step automated coding workflow in ModuleA is closely related to the operational needs of ModuleB, the Prompt Versioning Module. ModuleB's primary function is to manage versioning for prompts used in communications with a large language model. Since ModuleA includes steps that potentially require different versions of prompts for each step or sub-step in the workflow, especially those involving large language models, there is a functional overlap. The management of these workflows in ModuleA will likely necessitate the use of ModuleB's capabilities to handle different prompt versions effectively. The integration between the two modules would allow for efficient management of prompt versions corresponding to different steps in the automated coding workflow of ModuleA, ensuring that the correct version of the prompt is used at each stage. Therefore, the requirement from ModuleA has a direct functional relevance to the operations and capabilities of ModuleB.
Decision: Relevant



Second Time From ChatGPT:
Category: Workflow Management
Requirement: Define and manage a multi-step automated coding workflow.
Reasoning: The requirement to define and manage a multi-step automated coding workflow in ModuleA primarily focuses on the process of structuring and overseeing various coding tasks in a sequential or logical manner. This involves initializing, configuring, and executing different steps within a workflow. ModuleB, the Prompt Versioning Module, is centered around the management of prompt versions for entities communicating with large language models. There is no direct functional overlap between managing coding workflows and managing prompt versions. However, if ModuleB's functionality includes the need to handle different versions of prompts for each step in the coding workflow managed by ModuleA, then there is a partial relevance. ModuleB's role in providing versioned prompts could be an integral part of the communication steps within ModuleA's automated coding workflow. On the other hand, if ModuleB's scope is strictly limited to versioning prompts without any involvement in the broader workflow process of coding tasks, then the requirement from ModuleA is not relevant to ModuleB.
Decision: Partially Relevant (if ModuleB's prompt versioning functionality is used within ModuleA's coding workflow steps) / Not Relevant (if ModuleB's scope is strictly limited to prompt versioning without integration into ModuleA's workflow processes).

Third Time From ChatGPT:
Category: Workflow Management
Requirement: Define and manage a multi-step automated coding workflow.
Reasoning: The requirement to define and manage a multi-step automated coding workflow in ModuleA primarily focuses on the process of structuring and overseeing various coding tasks in a sequential or logical manner. This involves initializing, configuring, and executing different steps within a workflow. ModuleB, the Prompt Versioning Module, is centered around the management of prompt versions for entities communicating with large language models. There is no direct functional overlap between managing coding workflows and managing prompt versions. However, if ModuleB's functionality includes the need to handle different versions of prompts for each step in the coding workflow managed by ModuleA, then there is a partial relevance. ModuleB's role in providing versioned prompts could be an integral part of the communication steps within ModuleA's automated coding workflow. On the other hand, if ModuleB's scope is strictly limited to versioning prompts without any involvement in the broader workflow process of coding tasks, then the requirement from ModuleA is not relevant to ModuleB.
Decision: Partially Relevant (if ModuleB's prompt versioning functionality is used within ModuleA's coding workflow steps) / Not Relevant (if ModuleB's scope is strictly limited to prompt versioning without integration into ModuleA's workflow processes).