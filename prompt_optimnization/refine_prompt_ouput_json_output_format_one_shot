Prompt Description: This prompt is used to optimize a given prompt.


1. Version 1: use json as output
As an expert in optimizing prompts, your task is to refine the given prompt within the `>>Prompt<<` section. The start of content begins with `$start$` and ends with `$end$`.

Follow the steps below, each accompanied by a title and a description:
1. Analyze the Prompt:
   - Dissect the prompt to understand its content and objectives.

2. Determine the Domain:
   - Identify the domain to which this prompt belongs.

3. Evaluate and Recommend Linguistic Enhancements:
   - Articulate your thoughts on the prompt's clarity, effectiveness, sentence structure, consistency, coherence, and word order, content structure. If you think there are areas needs to be improved, then share your detailed opinions where and why

4. Present the Refined Prompt:
   - Apply your improvements suggestions from step 3, 4, and present the refined prompt from a new line

The output format should be in JSON, with each step title as the key, and the output of each step as the value. Here is an example format:
   {   
       "Analyze the Prompt": "Description of analysis...",
       "Summarize the Prompt": "Concise summary...",   
       "Identify the Domain of the Prompt": "Domain name...",
       "Assess and Suggest Improvements Based on the Domain of the Prompt": {
                 "a": "Opinions on clarity...",
                 "b": "Suggestions for improvement..."   
       },
       "Present the Refined Prompt": "$start$ Refined prompt content... $end$"
   }

>>Prompt<<
$start$
$end$


Version 2: Not using json output
As an expert in refining content prompts, your task is to improve the given prompt situated within the `[Prompt]` section. The content of the prompt is situated within the `$start$` and `$end$` tokens.


Follow the steps below, each accompanied by a title and a description:
1. Analyze the Prompt:
   - Dissect the prompt to understand its content and objectives.

2. Determine the Domain:
   - Identify the domain to which this prompt belongs.

3. Evaluate and Recommend Linguistic Enhancements:
   - Articulate your opinions on the prompt's clarity, accuracy, effectiveness, conciseness, sentence structure, consistency, coherence, and word order, content structure etc, usage of words etc. If you think there are areas needs to be improved, then share your detailed opinions where and why.

4. Present the Refined Prompt:
   - Apply your improvements suggestions from step 3, and present the refined prompt in a copiable code block


[Prompt]
$start$
As the best Python software engineer on earth, address the requriements outlined between the `$start$` and `$end$` tokens in the `[Requirement]` section.

[Guidelines]
- Use appropriate design patterns where neccessary. Think about refactoring for better modularity and easier testing.
- Follow SOLID principles and Python PEP8 coding best practices. Add type hints as well.
- Follow python docstring best practices, ensuring each file begins with a file-level docstring.
- Explain whether to create a new folder or use an existing one for file placement. Use descriptive naming conventions for files and folders that correlate with the requirement's features. For context, the current project's file structure looks like this:
    - src
        - ...
        - semantic_code
            - embedding
                - openai_embedding_creator.py
    - tests
        - unit_tests
            - ...
            - semantic_code
                - embedding
                    - test_openai_embedding_creator.py
        - integration_tests
            - ...
            - semantic_code
                - index
                    - test_index_service_integration.py
- Always use absolute imports over relative ones.
- Update docstrings in line with any code modifications.
- At last, use command write_file(file_path, content) to write the complete updated code to file path. Do not write to jupyter notebook. Use the following json format:
    command: write_file
    file_path: [here is the real file path] 
    content:
    ```
    Here is the complete content of the updated file.
    ```

Think step by step progressively and reason comphrehensively to address the task.
$end$




Version 3:
As an expert in refining writting, your task is to improve the given writting situated within the `[Writting]` section. The content of the writting is situated within the `$start$` and `$end$` tokens.


Follow the steps below, each accompanied by a title and a description:
1. Analyze the Prompt:
   - Dissect the prompt to understand its content and objectives.

2. Determine the Domain:
   - Identify the domain to which this prompt belongs.

3. Evaluate and Recommend Linguistic Enhancements:
   - Articulate your thoughts on the prompt's conciseness, clarity, accuracy, effectiveness, , sentence structure, consistency, coherence, and word order, content structure etc, usage of words etc. If you think there are areas needs to be improved, then share your detailed opinions where and why.

4. Present the Refined Prompt:
   - Apply your improvements suggestions from step 3, and present the refined prompt in a code block


[Writting]
$start$
As a top Vue3 frontend engineer, your task is to analyze the error and relevant codes, and based on your analysis results either propose a solution or add more debugging information for further analysis.

Follow the standards below:

- Examine the errors in the `[Error]` section and generate an initial hypothesis about their cause.

- Subsequently, walk through the referenced codes step by step in the `[Codes]` section to reason the possible cause of the error.

- In your response, clearly illustrate the code execution step by step using test data. Use the formats below depending on your findings:

  - Case 1: Able to pinpoint error code confidently:
    "The error message indicates that the issue is possibly caused by ____. Looking at the source code, we can see that the code performs ____, ____, and ____. These actions result in ____, which is likely the cause of the reported error." 

  - Case 2: Not able to pinpoint error code immediately :
    "The error indicates that the issue is possibly caused by ____. Looking at the source code, we can see that the code performs ____, ____, and ____. By just looking at the current code, i am not able to pinpoint the error code. I will add ____debugging  for another round of analysis."

- Propose Solutions or Debugging Steps:
  - For Case 1: Propose and implement a solution, explaining why each change is necessary and how it resolves the identified issue. 
  - For Case 2: Add additional logging in the source code to aid future analysis.

Think step by step, ensure your explanation is thorough, and that the reasoning process behind your analysis is comprehensive. Conclude with the complete updated code in a code block.
$end$



As an expert in refining writting, you are given a prompt in the `[Prompt]` section, and requirement in the `[Requirement]` section. The content of both section are situated within the `$start$` and `$end$` tokens. Your task is to analyse the prompt according to the requirement.


Follow the steps below, each accompanied by a title and a description:
1. Analyze the Prompt:
   - Dissect the prompt to understand its content and objectives.

2. Determine the Domain:
   - Identify the domain to which this prompt belongs.

3. Analyse the prompt according to the requirement.

[Prompt]
$start$
As a senior python software engineer, you are given a task situated between `$start$` and `$end` tokens in the `[Requirement]` section.

[Criterias]
- Follow python PEP8 best practices, such as typing etc.
- Follow pytest best practices when writting tests using fixtures, or mocking etc.
- Think about different test cases to improve test coverage
- Use behavior-driven naming conventions for the test function naming.
- Use best practices to create test file path. Here is a sample best practice to 
  put the test file for the source file.
    src
        semantic_code
                embedding
                    openai_embedding_creator.py
    tests
        unit_tests
            semantic_code
                embedding
                    test_openai_embedding_creator.py
        integration_tests
            semantic_code
                index
- Use command write_file(file_path, content) to write the complete updated code to file   path. 

Think step by step progressively and reason comprehensively to address the task. 

$end$


[Requirement]
$start$
The prompt is sent to the LLM. I want the LLM to perform a step-by-step thinking process, emulating a human approach. At the end, I want the LLM to include the text "write_file" in its output. My parser will search for the "write_file" keyword in the LLM's result.

By making this revision, it's clear that you are looking for the LLM to generate the text "write_file" within its response, rather than executing the function. This should eliminate any potential misunderstanding or ambiguity in the requirement.

Can you please improve the prompt please?
$end$