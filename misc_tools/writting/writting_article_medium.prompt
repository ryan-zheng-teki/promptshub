You are an AI. Your objective is to accomplish a large, complex task by employing the Task Decomposition and Role Assumption methodology. Break down the task into smaller, manageable subtasks, assign appropriate roles to each subtask, and actively execute each subtask by assuming the assigned roles to ensure high-quality results and successful completion of the entire task.

**Context**:
When faced with a large, complex task involving multiple people, humans employ a systematic approach to break it down into more manageable subtasks. This process involves analyzing the task, understanding its components, and planning the necessary steps and expertise required for each subtask. Throughout the decomposition process, humans iteratively define the Methodology for each subtask, which includes concrete instructions or algorithms specific to that subtask. Each step or instruction within the Methodology should be atomic, clear, and actionable, meaning it can be executed without the need for further breakdown. Based on the defined Methodology, they evaluate the size and complexity of each subtask and further divide it into smaller steps if necessary. This process is recursive until all subtasks, inputs, outputs, constraints, and Methodologies are thoroughly defined. Once the complete subtask structure is established, humans assign appropriate roles to each subtask based on the required expertise before presenting the thorough subtask result. They proceed with task execution by assuming the assigned roles and actively executing each subtask, following the developed Methodology and utilizing the output from previous steps as input for subsequent tasks.

**Criteria**:
- Break down the large, complex task into smaller, manageable subtasks.
- Iteratively define the Methodology for each subtask, including concrete instructions or algorithms specific to that subtask.
- Ensure each step or instruction within the Methodology is atomic, clear, and actionable, meaning it can be executed without the need for further breakdown.
- Evaluate the size and complexity of each subtask based on the defined Methodology and further divide it into smaller steps if necessary.
- Ensure all subtasks, inputs, outputs, constraints, and Methodologies are thoroughly defined before proceeding with task execution.
- Assign appropriate roles to each subtask based on the expertise required.
- Present the complete subtask structure, including well-defined input, output, methodology, role, and possibly constraints for each subtask.
- Actively execute each subtask by assuming the assigned role and following the developed Methodology.
- Utilize the output from completed subtasks as input for subsequent tasks.
- Ensure the successful completion of the entire task by effectively managing the task decomposition and role assumption process.

**Methodology**:
$start$
The Task Decomposition and Role Assumption methodology involves the following two phases:

Phase 1: Task Decomposition
1. Analyze the large, complex task and identify its components, objectives, and constraints.
2. Break down the task into smaller, more manageable subtasks.
3. For each subtask, iteratively:
   a. Define the Methodology, which could be an algorithm, step-by-step process, or analytical process. Ensure that the Methodology includes concrete instructions or algorithms specific to that subtask, providing clarity and thoroughness.
   b. Ensure each step or instruction within the Methodology is atomic, clear, and actionable, meaning it can be executed without the need for further breakdown.
   c. Based on the defined Methodology, evaluate the size and complexity of the subtask.
   d. If the subtask is deemed too large or complex, further divide it into smaller, manageable steps.
   e. Repeat steps 3a-3d until the subtask is of an appropriate size and complexity to yield high-quality results.
4. Define well-defined input and output for each subtask, ensuring clarity and specificity.
5. Establish criteria for each subtask to evaluate its completion and quality:
   - Identify the key requirements and objectives of the subtask.
   - Define measurable indicators or benchmarks to assess the subtask's progress and success.
   - Set specific quality standards or best practices that the subtask must meet.
   - Ensure the criteria align with the overall objectives and constraints of the main task.
6. Assign a specific role to each subtask, representing the expertise required to complete it.
7. Present the complete subtask structure, including well-defined input, output, methodology, role, criteria, and possibly constraints for each subtask.

Phase 2: Subtask Execution
8. Assume the appropriate role for each subtask and actively execute it:
   a. Utilize the input defined for the subtask.
   b. Apply the developed Methodology for the subtask, following the concrete instructions or algorithms specific to that subtask.
   c. Ensure that the subtasks are actively executed, not just planned. For example, if a subtask involves creating a Python script, then the final result of the subtask should be the script itself.
   d. Regularly evaluate the subtask execution against the established criteria to ensure quality and completeness.
9. Utilize the output from completed subtasks as input for subsequent tasks.
10. Present the final ultimate result, demonstrating the successful completion of the entire task by effectively integrating the outputs from all subtasks.
$end$

[OutputRules]
$RuleStart$
- Initiate each output with a variant of "I am currently...", followed by an action name, step description, major decision point, or any relevant task-specific detail. This flexible approach mirrors the human thought process, capturing the essence of transitioning between major points, steps, or actions, reflecting the dynamic and adaptable nature of human cognition. It reflects the dynamic and adaptable nature of human cognition, accommodating a wide range of contexts and tasks.

- Continuous Logical Flow: Ensure a continuous and logical progression of thoughts, maintaining coherence throughout the discourse. This principle guides the structuring of information to flow smoothly, mirroring the organized way humans tend to process and convey information.

- Meticulous Detail: Maintain meticulous attention to detail, demonstrating the thorough and careful consideration characteristic of human cognitive efforts. This rule emphasizes the importance of precision and accuracy in communication, reflecting the depth of human analysis and understanding.

- Conversational and Personal Language: Use language that is conversational and personal, akin to an individual's internal dialogue. This style brings out the human-like quality of the discourse, making the communication more relatable and engaging.

- Reasoning When Necessary: Include reasoning to precede actions or conclusions. This simulates the human cognitive process of thinking through a problem before arriving at a solution, ensuring that outputs are not only precise but also well-considered and justified.
$RuleEnd$

Follow the algorithm or methodogoy described in the `[Methodology]` section to perform the task, and the output should adhere to the `[OutputRules]`, ensuring a process that mirrors human-like cognitive process.

[Large Complex Task]
$start$
I have implemented a base class called UI Integrator. I experienced the need to open the browser for different tasks while building multiple RPA applications. These applications often have to open different tabs and cannot cooperate if they try to open the browser simultaneously. As a result, I frequently had to manually implement the process of opening and connecting to the browser, which I run in non-headless debug mode.

To address this, I created base classes that start only one browser instance, allowing multiple RPA applications to connect to it and open their pages without conflict. I found this implementation useful for other developers as well.

My task is to write a Medium article for developers, explaining this solution so they can use it for their own RPA applications that need to open a browser, a common requirement nowadays.

The article should be written in a developer-friendly manner.


Please read the source code in the CodeImplementation section, and write the article for me. Thank you very much.
$end

[CodeImplementation]
file: /home/ryan-ai/miniHDD/Learning/AFE/llm_ui_integration/llm_ui_integration/browser/config.toml
[browser]
chrome_profile_directory = "Profile 1"
remote_debugging_port = 9222
remote_host = "localhost"

file: /home/ryan-ai/miniHDD/Learning/AFE/llm_ui_integration/llm_ui_integration/browser/__init__.py


file: /home/ryan-ai/miniHDD/Learning/AFE/llm_ui_integration/llm_ui_integration/browser/browser_manager.py
import asyncio
import logging
from typing import Optional

from playwright.async_api import async_playwright
from playwright.async_api import Browser

from llm_ui_integration.browser.browser_launcher import is_browser_opened_in_debug_mode, launch_browser, remote_debugging_port
from llm_ui_integration.singleton_meta import SingletonMeta

logger = logging.getLogger(__name__)

class BrowserManager(metaclass=SingletonMeta):
    def __init__(self):
        self.browser_launch_lock = asyncio.Lock()
        self.browser_launched = False
        self.playwright: Optional[async_playwright] = None
        self.browser: Optional[Browser] = None

    async def is_browser_running(self) -> bool:
        try:
            return self.browser_launched or await is_browser_opened_in_debug_mode()
        except Exception as e:
            raise Exception(f"Error checking if browser is running: {str(e)}") from e

    async def launch_browser(self):
        if not await self.is_browser_running():
            async with self.browser_launch_lock:
                if not self.browser_launched:
                    await launch_browser()
                    self.browser_launched = True

    async def connect_browser(self) -> Browser:
        if self.browser is None:
            self.playwright = await async_playwright().start()
            endpoint_url = f"http://localhost:{remote_debugging_port}"
            self.browser = await self.playwright.chromium.connect_over_cdp(endpoint_url)
        return self.browser

    async def stop_browser(self):
        if self.browser is not None:
            await self.browser.close()
            self.browser = None
        if self.playwright is not None:
            await self.playwright.stop()
            self.playwright = None
        self.browser_launched = False


file: /home/ryan-ai/miniHDD/Learning/AFE/llm_ui_integration/llm_ui_integration/browser/browser_launcher.py
import os
import sys
import subprocess
import socket
import asyncio

from llm_ui_integration.config.config_parser import EnvironmentConfigParser, TOMLConfigParser

async def launch_browser():
    if sys.platform == 'linux':
        executable_path = '/usr/bin/google-chrome' 
        user_data_dir = os.path.join(os.path.expanduser('~'), '.config', 'google-chrome')
    elif sys.platform == 'darwin':  # macOS
        executable_path = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'
        user_data_dir = os.path.join(os.path.expanduser('~'), 'Library', 'Application Support', 'Google', 'Chrome')
    else:
        raise Exception("Unsupported OS. This script supports Linux and macOS only.")

    args = [
        "--no-first-run",
        "--flag-switches-begin",
        "--flag-switches-end",
        f"--remote-debugging-port={remote_debugging_port}",
        f"--profile-directory={chrome_profile_directory}",
        f"--user-data-dir={user_data_dir}"
    ]

    subprocess.Popen([executable_path] + args)
    await wait_for_browser_start()

async def is_browser_opened_in_debug_mode():
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as sock:
            sock.settimeout(1)
            result = sock.connect_ex((remote_host, remote_debugging_port))
            return result == 0
    except ConnectionRefusedError as error:
        print(error)
        return False

async def wait_for_browser_start(timeout=20, retry_interval=1):
    start_time = asyncio.get_event_loop().time()
    while not await is_browser_opened_in_debug_mode():
        if asyncio.get_event_loop().time() - start_time > timeout:
            raise TimeoutError(f"Timed out waiting for port {remote_debugging_port} to listen")
        await asyncio.sleep(retry_interval)

def get_browser_config():
    if "BROWSER_CONFIG_PATH" in os.environ:
        config_parser = EnvironmentConfigParser("BROWSER_CONFIG_PATH")
        browser_config = config_parser.parse()
    else:
        current_file = os.path.realpath(__file__)
        config_file = os.path.join(os.path.dirname(current_file), "config.toml")
        config_parser = TOMLConfigParser()
        browser_config = config_parser.parse(config_file)
    
    # Override chrome_profile_directory if CHROME_PROFILE_DIRECTORY environment variable is set
    if "CHROME_PROFILE_DIRECTORY" in os.environ:
        browser_config["browser"]["chrome_profile_directory"] = os.environ["CHROME_PROFILE_DIRECTORY"]
    
    return browser_config

# Load browser configuration
browser_config = get_browser_config()

chrome_profile_directory = browser_config.get("browser", {}).get("chrome_profile_directory", "Default")
remote_debugging_port = browser_config.get("browser", {}).get("remote_debugging_port", 9222)
remote_host = browser_config.get("browser", {}).get("remote_host", "localhost")


file: /home/ryan-ai/miniHDD/Learning/AFE/llm_ui_integration/llm_ui_integration/ui_integrator.py
import asyncio
from abc import ABC
import logging
from typing import Optional

from playwright.async_api import Browser, BrowserContext, Page

from llm_ui_integration.browser.browser_manager import BrowserManager

logger = logging.getLogger(__name__)

class UIIntegrator:
    def __init__(self):
        self.browser_manager = BrowserManager()
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        self.initialized = False

    async def initialize(self):
        await self.browser_manager.launch_browser()
        browser = await self.browser_manager.connect_browser()
        self.context = browser.contexts[0]
        self.page = await self.context.new_page()
        self.initialized = True
        logger.info("UIIntegrator initialized successfully")

    async def reopen_page(self):
        if not self.initialized:
            logger.error("UIIntegrator is not initialized. Call initialize() first.")
            raise RuntimeError("UIIntegrator is not initialized")

        try:
            if self.page:
                await self.page.close()
                logger.info("Closed existing page")

            self.page = await self.context.new_page()
            logger.info("Opened new page")
        except Exception as e:
            logger.error(f"Error while reopening page: {str(e)}")
            raise

    async def close(self, close_context=True):
        try:
            if self.page:
                await self.page.close()
                self.page = None
                logger.info("Closed page")

            if close_context and self.context:
                await self.context.close()
                self.context = None
                logger.info("Closed context")

            if close_context:
                await self.browser_manager.stop_browser()
                logger.info("Stopped browser")

            self.initialized = False if close_context else self.initialized
        except Exception as e:
            logger.error(f"Error while closing: {str(e)}")
            raise


file: /home/ryan-ai/miniHDD/Learning/AFE/llm_ui_integration/llm_ui_integration/singleton_meta.py
from abc import ABCMeta

class SingletonMeta(type):
    """
    SingletonMeta is a metaclass that implements the Singleton design pattern.
    It ensures that a class using this metaclass can have only one instance.
    """
    _instances = {}

    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super().__call__(*args, **kwargs)
        return cls._instances[cls]

class ABCSingletonMeta(SingletonMeta, ABCMeta):
    pass